# Desafio T√©cnico - Cientista de Dados J√∫nior
# Candidata - Nayara Valevskii

Para este desafio ser√° necess√°rio ter acesso ao Google Cloud Platform (GCP) para utilizar o BigQuery, onde ser√£o visualizados e consultados os dados dispon√≠veis no projeto `datario`.

## 1- An√°lise SQL - GCP

1. Ir at√© o [GCP Console](https://console.cloud.google.com/) e criar uma conta Google ou utilizar a sua conta existente para realizar login
2. Criar ou selecionar um projeto existente com a op√ß√£o *Sem organiza√ß√£o*
3. Na barra de pesquisas ou no menu lateral procurar pelo *BigQuery*, que √© onde iremos acessar os dados
4. Ap√≥s entrar no console do *BigQuery*, iremos adicionar um novo projeto clicando em "+ Adicionar Dados" na barra Explorer.
5. Em seguida, clique em "Fixar projeto por nome" e procure pelo projeto **datario**.
6. Agora o projeto datario j√° est√° dispon√≠vel na nossa barra explorer e podemos realizar nossas consultas.
7. Clicando no bot√£o *New Query* √© poss√≠vel adicionar uma consulta SQL. As consultas deste projeto est√£o na p√°gina [analise_sql](https://github.com/nayarawakewski/emd-desafio-junior-data-scientist/blob/desafio-nayara-valevskii/analise_sql.sql). Para visualizar, copie o trecho de uma das consultas, cole na caixa de texto e clique em **Run**/**Executar** (N√£o consultar as querys todas de uma vez, por conta do tamanho da base, as consultas ficaram lentas; opte por consultar trecho por trecho).


---
## 2- An√°lise Python - Jupyter Notebook
1. Entre no site do Google Colabory, essa √© a forma mais f√°cil e sem necessidade de instalar sistemas na m√°quina: [analise_sql](https://colab.research.google.com/?hl=pt_BR)
2. Em seguida, clique em `fazer login`, acesse com sua conta do Google.
3. Abrir√° uma p√°gina para voc√™ importar um arquivo notebook jupyter, que ser√° o arquivo `analise_sql.ipynb` que est√° nesse reposit√≥rio. Lembre-se de clonar esse reposit√≥rio antes ou baixar o arquivo jupyter.
4. Ap√≥s importar o arquivo `analise_sql.ipynb` para o Colab, voc√™ pode executar as c√©lulas para ver as an√°lises em Python.
5. Execute primeiro as atualiza√ß√µes das bibliotecas do Google, ap√≥s isso execute a c√©lua de instala√ß√£o da biblioteca `basedosdados`, essa biblioteca far√° a conex√£o com os dados da base `datario`.
6. Para baixar os dados utilizando a biblioteca **basedosdados** ser√° necess√°rio utilizar o ID do projeto criado anteriormente no GCP. Para isso, clique no nome do projeto ou em "Selecionar um projeto" no Console do GCP e copie o **ID** do projeto.
7. Nas c√©lulas de sele√ß√£o das tabelas, voc√™ ir√° alterar o trecho:
```sql
query, billing_project_id="ID DO SEU PROJETO", reauth = True
```
   Esse ID do projeto ser√° utilizado no notebook `analise_python.ipynb`.
   
8. Agora √© poss√≠vel executar todas as c√©lulas presentes no notebook e visualizar as an√°lises em Python.

   Para mais detalhes, verifique o tutorial a seguir: [Como acessar dados no BigQuery](https://docs.dados.rio/tutoriais/como-acessar-dados/#como-criar-uma-conta-na-gcp)

---


## 3- Visualiza√ß√£o de Dados - PowerBi

1. Para criar a visualiza√ß√£o em PowerBi, foi salvo os dataframes df_chamados_1746 e df_bairros, da an√°lise em Python feito anteriormente em extens√£o CSV.
2. Foi utilizado o Figma para fazer os frames (Telas) das p√°ginas do PowerBi, foi considerado  como base o layout do site Chamado 1746 do Rio de Janeiro.
3. Foram criadas algumas an√°lises:

- P√°gina 1: `Total Chamados`, `Chamados Resolvidos`, `Chamados N√£o Resolvidos`, `TopN5 Tipos de Chamados`;
- P√°gina 2: `TopN5 Tipos de Chamados N√£o Resolvidos`;
- P√°gina 3: `TopN5 Bairros com Chamados N√£o Resolvidos`;
- Filtros das P√°ginas: `Ano`, `M√™s`, `Tipo Chamado`, `Subprefeitura`, `Bairro`;

Para visualizar o dashboard, acesso o link abaixo:

[An√°lise Chamados ](https://app.powerbi.com/view?r=eyJrIjoiODc1ZWJkMTUtZmU3ZC00ZDdlLWI0ZWYtY2YxMWRiZjRjNmNkIiwidCI6ImVjYTFhZTJkLWU5MjktNGM2OS1iZmEyLTAxNWQ0YzQ3OGY4YSJ9)

## 4- Considera√ß√µes

A id√©ia inicial era criar um aplicativo e dashboard no Streamlit, mas por conta do tamanho da base de dados, o aplicativo ficou muito lento, mesmo dividindo a base em v√°rios dataframes e an√°lises menores. Por este motivo foi optado por utilizar o PowerBi, optando por fazer an√°lises mais simples, mais explicando o entendimento de cada an√°lise feita.

## üéÅ Express√µes de gratid√£o

* Obrigada pela oportunidade de participar do processo seletivo üì¢;

---
‚å®Ô∏è com ‚ù§Ô∏è por [Nayara Vakevskii](https://github.com/NayaraWakewski) üòä
